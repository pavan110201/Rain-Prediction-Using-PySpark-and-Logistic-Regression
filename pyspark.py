# -*- coding: utf-8 -*-
"""Pyspark.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15oTMIbAossbEZs3Wymx0mf-w5QTVlD1e
"""

#Installing PySpark
!pip install pyspark

# Libraries
import os, sys, tempfile, shutil
import pyspark.sql.functions as F
from pyspark.sql import SparkSession
from pyspark.sql.types import *
from pyspark.mllib.stat import Statistics
from pyspark.mllib.util import MLUtils
from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler, Imputer, StandardScaler
from pyspark.ml import Pipeline
from pyspark.ml.classification import LogisticRegression
from pyspark.ml.tuning import ParamGridBuilder, CrossValidator
from pyspark.sql.functions import col, expr, isnan, when, count, year, month, dayofmonth, lit
from pyspark.ml.classification import LinearSVC
from pyspark.ml.feature import MinMaxScaler
from pyspark.ml.linalg import Vectors
from pyspark.ml import Pipeline
from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator
from pyspark.ml.classification import LogisticRegressionModel
from pyspark.mllib.evaluation import MulticlassMetrics
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Force remount to override previous mount attempts.
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

#Creating a Spark Session
from pyspark.sql import SparkSession
spark = SparkSession.builder.master("local[*]").appName("weatherAUS.csv").getOrCreate()

# Load the weatherAUS.csv file into a Spark DataFrame
dataset = spark.read.csv('/content/drive/MyDrive/Rain Prediction/weatherAUS.csv', header=True, inferSchema=True)

#Displaying the dataset
dataset.show(5)

num_rows = dataset.count()
num_columns = len(dataset.columns)

# Display the shape (rows, columns)
print(f"Dataset Shape: ({num_rows}, {num_columns})")

#Schema of Dataset
dataset.printSchema()

"""1) Exploring categorical variable names"""

#converting strings to float
dataset = dataset.select(*(col(c).cast(FloatType()) if c in ["MinTemp","MaxTemp","Rainfall","Evaporation","WindGustSpeed","WindSpeed9am","Sunshine","WindSpeed3pm", "Humidity9am", "Humidity3pm", "Pressure9am", "Pressure3pm", "Cloud9am", "Cloud3pm", "Temp9am", "Temp3pm", "RISK_MM"
] else col(c) for c in dataset.columns))

dataset.printSchema()

"""2) Numerical Variables"""

#printing numerical variables in the dataset
numerical_columns = [field.name for field in dataset.schema if isinstance(field.dataType, (IntegerType, FloatType, DoubleType))]
print("Columns containing numerical values:", numerical_columns)

"""3) categorical variables"""

#printing categorical variables in the dataset
string_columns = [field.name for field in dataset.schema if isinstance(field.dataType, StringType)]
print("Columns containing string values:", string_columns)

"""4) Null Values in Numerical Variables"""

from pyspark.sql import Row

# Find numerical columns with null values and their counts, and filter non-zero counts
numerical_null_counts = [(c, dataset.filter(col(c).isNull() | isnan(c)).count()) for c in numerical_columns]

# Filter columns with non-zero null counts
numerical_columns_with_null = [(c, count) for c, count in numerical_null_counts if count > 0]

# Create a DataFrame for the result
dataset_nv = spark.createDataFrame(numerical_columns_with_null, ["Column Name", "Null Count"])

# Show the result as a table
dataset_nv.show()

"""5) Null Values in Categorical Variables"""

# Find columns with null values and their counts, and filter non-zero counts
categorical_null_counts = {c: dataset.filter( col(c).isin('None', 'NULL', 'NA') | (col(c) == '') | col(c).isNull() | isnan(c) ).count() for c in string_columns}

# Filter columns with non-zero null counts
categorical_columns_with_null = [(c, count) for c, count in categorical_null_counts.items() if count > 0]

# Create a DataFrame for the result
dataset_cv = spark.createDataFrame(categorical_columns_with_null, ["Column Name", "Null Count"])

# Show the result as a table
dataset_cv.show()

"""6) Frequency count of each numerical variable"""

for column in numerical_columns:
    # Group by the column on the original dataset (dataset)
    frequency_count = dataset.groupBy(column).count()
    print(f"\nFrequency count for '{column}':")
    frequency_count.show(100, truncate=False)  # Show the frequency count for the first 100 unique values
    distinct_values_count = dataset.select(column).distinct().count()
    print(f"Number of distinct datapoints for {column}: {distinct_values_count}")
    print()

"""7) Frequency count of each categorical variable"""

#Printing Frequency count of categorical variables
for column in string_columns:
    # Group by the column on the original dataset (dataset) instead of dataset_cv
    frequency_count = dataset.groupBy(column).count()
    print(f"\nFrequency count for '{column}':")
    frequency_count
    frequency_count.show(100,truncate=False)
    distinct_values_count = dataset.select(column).distinct().count()
    print(f"Number of datapoints in each distinct value for {column}: {distinct_values_count}")
    print()

"""8) Dropping Risk Column"""

#Dropping risk column
dataset = dataset.drop("RISK_MM")

"""9) Summary of the Dataset"""

#summary of the data
dataset.summary().show()

"""10) Decomposing the Date Field"""

#Decomposing date field
dataset = dataset.withColumn("Year", year(col("Date"))) \
         .withColumn("Month", month(col("Date"))) \
         .withColumn("Day", dayofmonth(col("Date")))
dataset = dataset.drop("Date")

dataset.show(5)

"""11) Replacing null values of data with median for numerical variables"""

#Replacing null values of data with median for numericals
medians = {}
for column in numerical_columns:
    median_value = dataset.approxQuantile(column, [0.5], 0.01)[0]
    medians[column] = median_value
for column in numerical_columns:
    median_value = medians[column]
    dataset = dataset.withColumn(column, when(col(column).isNull(), median_value).otherwise(col(column)))

dataset.show(5)

"""13) Replacing null values of data with mode for categorical variables"""

#Replacing null values of data with mode for categrical
for column in string_columns:
    mode_value = dataset.groupBy(column).count().orderBy("count", ascending=False).first()[0]
    dataset = dataset.fillna({column: mode_value})

dataset.show(5)

"""14) performing one hot encoding"""

# OneHotEncoding for string columns
indexers = [StringIndexer(inputCol=column, outputCol=column + "_index", handleInvalid="keep") for column in string_columns]
encoders = [OneHotEncoder(inputCol=indexer.getOutputCol(), outputCol= indexer.getInputCol() + "_vec") for indexer in indexers]

"""15) RainTomorrow is the label, and all other fields are features"""

# Using vec_Assembler to assemble features into a single vector
vec_assembler = VectorAssembler(inputCols=[
    'MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm',
    'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm', 'Year', 'Month', 'Day',
    'Location_vec', 'WindGustDir_vec', 'WindDir9am_vec', 'WindDir3pm_vec', 'RainToday_vec'
], outputCol='features')
label_indexer = StringIndexer(inputCol="RainTomorrow", outputCol="RainTomorrowLabel")

"""16) Normalization of data"""

# Initialize MinMaxScaler
scaler = MinMaxScaler(inputCol="features", outputCol="normalized_features")

"""17) Training with Logistic Regression model on the training dataset (80%, 20% split)."""

lr_model = LogisticRegression(featuresCol="normalized_features", labelCol="RainTomorrowLabel")

#Creating pipeline
pipeline_lr = Pipeline(stages=indexers + encoders + [vec_assembler, scaler, label_indexer, lr_model])
pipeline_lr.getStages()

#spliting the dataset
train_data, test_data = dataset.randomSplit([0.8,0.2], seed=64)
print("Number of rows in training set:", train_data.count())
print("Number of rows in testing set:", test_data.count())

fit_model_lr = pipeline_lr.fit(train_data)
results_lr = fit_model_lr.transform(test_data)
#printing the results of the model
results_lr.show(10)

"""18) Testing for LogisticRegression Model"""

#performing testing for LogisticRegression Model
my_eval_lr = BinaryClassificationEvaluator(rawPredictionCol='prediction',
                                       labelCol='RainTomorrowLabel')
results_lr.select('RainTomorrowLabel','prediction').show(100)

"""19) Performing Training for SVM Model"""

# Building SVM Model
svm_model = LinearSVC(featuresCol="normalized_features", labelCol="RainTomorrowLabel")

# Creating the pipeline
pipeline_svm = Pipeline(stages=indexers + encoders + [vec_assembler, scaler, label_indexer, svm_model])

train_data, test_data = dataset.randomSplit([0.8,0.2], seed=64)
print("Number of rows in training set:", train_data.count())
print("Number of rows in testing set:", test_data.count())

# Fit the pipeline
fit_model_svm = pipeline_svm.fit(train_data)
results_svm = fit_model_svm.transform(test_data)
results_lr.show(10)

"""20) Testing the SVM Model"""

# Performing testing
my_eval_svm = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='RainTomorrowLabel')

# Show the results of the prediction
results_svm.select('RainTomorrowLabel', 'prediction').show(100)

"""21) Confusion Matrix for Logstic Regression"""

pred_and_labels = results_lr.select("prediction", "RainTomorrowLabel").rdd
metrics = MulticlassMetrics(pred_and_labels)
confusion_matrix = metrics.confusionMatrix().toArray()
plt.figure(figsize=(6, 5))
sns.heatmap(confusion_matrix, annot=True, fmt=".0f", cmap="Blues", xticklabels=["Negative", "Positive"], yticklabels=["Negative", "Positive"])  # Changed fmt to ".0f"
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - Logistic Regression')
plt.show()

"""22) Accuracy & F1 Score for Logstic Regression"""

# Evaluating the model: Accuracy using MulticlassClassificationEvaluator
accuracy_eval = MulticlassClassificationEvaluator(labelCol="RainTomorrowLabel", predictionCol="prediction", metricName="accuracy")
accuracy = accuracy_eval.evaluate(results_lr)
print(f"Accuracy: {accuracy:.10f}")

# Evaluating the model: F1 score using MulticlassClassificationEvaluator
f1_eval = MulticlassClassificationEvaluator(labelCol="RainTomorrowLabel", predictionCol="prediction", metricName="f1")
f1_score = f1_eval.evaluate(results_lr)
print(f"F1 Score: {f1_score:.10f}")

"""23) Confusion Matrix for SVM"""

pred_and_labels = results_svm.select("prediction", "RainTomorrowLabel").rdd
metrics = MulticlassMetrics(pred_and_labels)
confusion_matrix = metrics.confusionMatrix().toArray()
plt.figure(figsize=(6, 5))
sns.heatmap(confusion_matrix, annot=True, fmt=".0f", cmap="Blues", xticklabels=["Negative", "Positive"], yticklabels=["Negative", "Positive"])  # Changed fmt to ".0f"
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - SVM')
plt.show()

"""24) Accuracy & F1 Score for SVM"""

# Evaluating the model: Accuracy using MulticlassClassificationEvaluator
accuracy_eval = MulticlassClassificationEvaluator(labelCol="RainTomorrowLabel", predictionCol="prediction", metricName="accuracy")
accuracy = accuracy_eval.evaluate(results_svm)
print(f"Accuracy: {accuracy:.10f}")

# Evaluating the model: F1 score using MulticlassClassificationEvaluator
f1_eval = MulticlassClassificationEvaluator(labelCol="RainTomorrowLabel", predictionCol="prediction", metricName="f1")
f1_score = f1_eval.evaluate(results_svm)
print(f"F1 Score: {f1_score:.10f}")